<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="Amit Rajan">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://amitrajan012.github.io/img/head.jpg">
    <meta property="twitter:image" content="https://amitrajan012.github.io/img/head.jpg" />
    

    
    <meta name="title" content="Think Stats: Chapter 8" />
    <meta property="og:title" content="Think Stats: Chapter 8" />
    <meta property="twitter:title" content="Think Stats: Chapter 8" />
    

    
    <meta name="description" content="Think Stats: Chapter 8">
    <meta property="og:description" content="Think Stats: Chapter 8" />
    <meta property="twitter:description" content="Think Stats: Chapter 8" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="Amit, Rajan, ML, Data, Science, Blockchain">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>Think Stats: Chapter 8-Amit Rajan Blog</title>

    <link rel="canonical" href="/post/chapter-8-estimation/">

    
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hugo-theme-cleanwhite.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" rel="stylesheet" type="text/css">

    
    

    

    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
    }});</script>

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
    <script src="/js/jquery.min.js"></script>

    
    <script src="/js/bootstrap.min.js"></script>

    
    <script src="/js/hux-blog.min.js"></script>

    
    

</head>




<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Amit Rajan</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                        
                    
                    
		    
                        <li><a href="/top/about/">ABOUT</a></li>
                    

                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/head.jpg')
    }
</style>

<header class="intro-header" >

    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/think-stats" title="Think Stats">
                            Think Stats
                        </a>
                        
                        <a class="tag" href="/tags/estimation" title="Estimation">
                            Estimation
                        </a>
                        
                        <a class="tag" href="/tags/exponential-distribution" title="Exponential Distribution">
                            Exponential Distribution
                        </a>
                        
                        <a class="tag" href="/tags/confidence-intervals" title="Confidence Intervals">
                            Confidence Intervals
                        </a>
                        
                        <a class="tag" href="/tags/bayesian-estimation" title="Bayesian Estimation">
                            Bayesian Estimation
                        </a>
                        
                    </div>
                    <h1>Think Stats: Chapter 8</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        
                            Posted by 
                            
                                    Amit Rajan
                             
                            on 
                            Tuesday, September 4, 2018
                            
                            
                            
                            
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <h3 id="81-the-estimation-game">8.1 The estimation game</h3>
<p>In a rudimentary way, <b>sample mean</b> can be used to estimate a distribution. The process is called <b>estimation</b> and the statistic we used (sample mean) is called an <b>estimator</b>. If there are no <b>outliers</b>, sample mean minimizes the <b>mean squared error (MSE)</b>. A <b>maximum likelihood estimator (MLE)</b> is an estimator that has the highest chance of being right (value with highest probability).</p>
</br>
<p><b>Exercise 8.1:</b> Write a function that draws 6 values froma normal distribution with $\mu$ = 0 and $\sigma$ = 1. Use the sample mean to estimate m and compute the error $\bar{x} - \mu$. Run the function 1000 times and compute MSE.</p>
<p>Now modify the program to use the median as an estimator. Compute MSE again and compare to the MSE for $\bar{x}$.</p>
<p><b>Solution:</b> MSE for mean as the estimator is less.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> norm
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>norm <span style="color:#f92672">=</span> norm(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>count <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>MSE_mean <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>MSE_median <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, count):
</span></span><span style="display:flex;"><span>    rvs <span style="color:#f92672">=</span> norm<span style="color:#f92672">.</span>rvs(size<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span>)
</span></span><span style="display:flex;"><span>    sample_mean <span style="color:#f92672">=</span> rvs<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>    sample_median <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>median(rvs)
</span></span><span style="display:flex;"><span>    MSE_mean <span style="color:#f92672">+=</span> (sample_mean<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>    MSE_median <span style="color:#f92672">+=</span> (sample_median<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;MSE when maen is the estimator is: &#34;</span> <span style="color:#f92672">+</span>str(MSE_mean<span style="color:#f92672">/</span>count))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;MSE when madian is the estimator is: &#34;</span> <span style="color:#f92672">+</span>str(MSE_median<span style="color:#f92672">/</span>count))
</span></span></code></pre></div><pre><code>MSE when maen is the estimator is: 0.16503949703743645
MSE when madian is the estimator is: 0.20949112657014224
</code></pre>
<h3 id="82-guess-the-variance">8.2 Guess the variance</h3>
<p>For the estimation of variance of a distribution, sample variance which is defined as follows is an adequate estimator for large sample size.</p>
<p>$$S^{2} = \frac{1}{n}\sum(x_{i} - \bar{x})^{2}$$</p>
<p>But for small sample sizes, it tends to be low and is called a <b>biased estimator</b>. An estimator is <b>unbiased</b> if the expected total (or mean) error, after many iterations of the estimation is 0. There is another simple statistic that is an unbiased estimator of $\sigma^{2}$, which is given as:</p>
<p>$$S^{2} = \frac{1}{n-1}\sum(x_{i} - \bar{x})^{2}$$</p>
<p><b>Exercise 8.2:</b> Write a function that draws 6 values froma normal distribution with $\mu$ = 0 and $\sigma$ = 1. Use the sample variance to estimate s2 and compute the error $S^{2} - \sigma^{2}$. Run the function 1000 times and compute mean error (not squared).</p>
<p>Now modify the program to use the unbiased estimator $S^{2}_{n-1}$. Compute the mean error again and see if it converges to zero as you increase the number of games.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> norm
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>norm <span style="color:#f92672">=</span> norm(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>count <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>mean_error_S <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>mean_error_S_n1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>sample_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(count):
</span></span><span style="display:flex;"><span>    rvs <span style="color:#f92672">=</span> norm<span style="color:#f92672">.</span>rvs(size<span style="color:#f92672">=</span>sample_size)
</span></span><span style="display:flex;"><span>    sample_mean <span style="color:#f92672">=</span> rvs<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>    sample_variance <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>square(rvs <span style="color:#f92672">-</span> sample_mean))
</span></span><span style="display:flex;"><span>    mean_error_S <span style="color:#f92672">+=</span> abs((sample_variance) <span style="color:#f92672">/</span> (sample_size) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>    mean_error_S_n1 <span style="color:#f92672">+=</span> abs((sample_variance) <span style="color:#f92672">/</span> (sample_size<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Mean error for biased estimator of variance: &#34;</span> <span style="color:#f92672">+</span>str(mean_error_S<span style="color:#f92672">/</span>count))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Mean error for unbiased estimator of variance: &#34;</span> <span style="color:#f92672">+</span>str(mean_error_S_n1<span style="color:#f92672">/</span>count))
</span></span></code></pre></div><pre><code>Mean error for biased estimator of variance: 0.034980760578752344
Mean error for unbiased estimator of variance: 0.034968783350441
</code></pre>
<h3 id="84-exponential-distributions">8.4 Exponential distributions</h3>
<p>For an exponential distribution, the <b>MLE estimator</b> for the parameter $\lambda$ is 1\ $\bar{x}$, where $\bar{x}$ is the mean. An alternate is the estimation based on median. As for an exponential distribution, median is given as:</p>
<p>$$\mu_{\frac{1}{2}} = \frac{ln(2)}{\lambda}$$</p>
<p>and hence the estimator based on median is:</p>
<p>$$\bar{\lambda} = \frac{ln(2)}{\mu_{\frac{1}{2}}}$$</p>
<p><b>Exercise 8.3:</b> Run an experiment to see which of mean and median estimator yields lower MSE. Test whether either of them is biased.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> expon
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pylab <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>expon <span style="color:#f92672">=</span> expon(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) <span style="color:#75715e"># lambda = 1</span>
</span></span><span style="display:flex;"><span>count <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>samples <span style="color:#f92672">=</span> [<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">100</span>]
</span></span><span style="display:flex;"><span>error_mean <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>error_median <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> sample_size <span style="color:#f92672">in</span> (samples):
</span></span><span style="display:flex;"><span>    e_mean <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    e_median <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, count):
</span></span><span style="display:flex;"><span>        rvs <span style="color:#f92672">=</span> expon<span style="color:#f92672">.</span>rvs(size<span style="color:#f92672">=</span>sample_size)
</span></span><span style="display:flex;"><span>        sample_mean <span style="color:#f92672">=</span> rvs<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>        sampel_median <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>median(rvs)
</span></span><span style="display:flex;"><span>        lamba_mean <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>sample_mean
</span></span><span style="display:flex;"><span>        lambda_median <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>log(<span style="color:#ae81ff">2</span>)<span style="color:#f92672">/</span>sample_median
</span></span><span style="display:flex;"><span>        e_mean <span style="color:#f92672">+=</span> (lamba_mean <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>        e_median <span style="color:#f92672">+=</span> (lambda_median <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    error_mean[sample_size] <span style="color:#f92672">=</span> e_mean <span style="color:#f92672">/</span> count
</span></span><span style="display:flex;"><span>    error_median[sample_size] <span style="color:#f92672">=</span> e_median <span style="color:#f92672">/</span> count
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">8</span>))
</span></span><span style="display:flex;"><span>l1 <span style="color:#f92672">=</span> sorted(error_mean<span style="color:#f92672">.</span>items()) <span style="color:#75715e"># sorted by key, return a list of tuples</span>
</span></span><span style="display:flex;"><span>x, y <span style="color:#f92672">=</span> zip(<span style="color:#f92672">*</span>l1) <span style="color:#75715e"># unpack a list of pairs into two tuples</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(x, y, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;r&#34;</span>, marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;o&#34;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MSE (mean)&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Number of Samples&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;MSE&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;best&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><img class="pure-img" src="/img/Chapter%208%20-%20Estimation_files/Chapter%208%20-%20Estimation_9_0.png" alt="">
<h3 id="85-confidence-intervals">8.5 Confidence intervals</h3>
<p>So far we have been doing <b>point estimates</b>. <b>Confidenc Intervals</b> is a range in which there is certain percent of chance of the value estimated to lie in. In general, confidence intervals are hard to compute analytically but relatively easy to estimate using simulation.</p>
<h3 id="86-bayesian-estimation">8.6 Bayesian estimation</h3>
<p>If a 90% confidence interval is computed, it can be said that the true value of the parameter has a 90% chance of falling in the interval. But from a frequentist point if view, the parameter is an unknown but fixed value and hence it is either in the interval we computed or not.</p>
<h3 id="87-implementing-bayesian-estimation">8.7 Implementing Bayesian estimation</h3>
<p>Prior distribution can be represented by PMF or CDF but PMF is a natural choice as we want to map from a hypothesis to a probability. Each value in PMF represents a hypothesis; for example, the value 0.5 represents that $\lambda$ is 0.5.</p>
<p>Bayesian estimation can be explained as a case: there is a room full of people, where each person has a different guess about whatever we are trying to estimate. Initially, each person has a degree of confidence about their own hypothesis. After seeing the evidence, each person updates their confidence based on P(E|H), the likelihood of the evidence, given their hypothesis. As a result, some people get more confident and some less about their guess depending on the relative likelihood of their hypothesis.</p>
<p><b>Exercise 8.5:</b> In the 2008 Minnesota Senate race the final vote count was 1,212,629 votes for Al Franken and 1,212,317 votes for Norm Coleman. Franken was declared the winner, but as Charles Seife points out in Proofiness, the margin of victory was much smaller than the margin of error, so the result should have been considered a tie.</p>
<p>Assuming that there is a chance that any vote might be lost and a chance that any vote might be double-counted, what is the probability that Coleman actually received more votes?</p>
<p><b>Solution:</b> We choose to model the votes as Poisson distributions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> poisson
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>franken_dist <span style="color:#f92672">=</span> poisson<span style="color:#f92672">.</span>rvs(<span style="color:#ae81ff">1212629</span>, size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>coleman_dist <span style="color:#f92672">=</span> poisson<span style="color:#f92672">.</span>rvs(<span style="color:#ae81ff">1212317</span>, size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> franken_dist[i] <span style="color:#f92672">&lt;</span> coleman_dist[i]:
</span></span><span style="display:flex;"><span>        count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Probability of Coleman getting more votes is: &#34;</span> <span style="color:#f92672">+</span> str(count<span style="color:#f92672">/</span><span style="color:#ae81ff">1000</span>))
</span></span></code></pre></div><pre><code>Probability of Coleman getting more votes is: 0.405
</code></pre>
<h3 id="89-the-locomotive-problem">8.9 The locomotive problem</h3>
<p>The locomotive problem is a classic problem in probability. The statement is:</p>
<p>A railraod number its locomotive in order 1..N. One day you see a locomotive with the number 60. Estimate how many locomotives the railroad has.</p>
<p>Suppose that there are N trains and every time we play the estimation game, we see train $i$ and guess $ai$, so the squared error is $(ai-N)^{2}$. If we play the game N times and see each train once, the mean squared error is</p>
<p>$$MSE = \frac{1}{N}\sum_{i=1}^{N}(ai-N)^{2}$$</p>
<p>To minimize the MSE, we take the derivative with respect to a:</p>
<p>$$\frac{dMSE}{da} = \frac{1}{N}\sum_{i=1}^{N}2i(ai-N) = 0$$</p>
<p>Solving for a we get,</p>
<p>$$a = \frac{3N}{2N+1}$$</p>
<p>It does not seem very useful as for the estimation, we need to know N, which we have to estimate. Though, for large value of N, the value of a converges to 3/2 and we could choose 3i/2 as the estimator.</p>
<p>To find an unbiased estimator, we can compute the mean error(ME) as:</p>
<p>$$ME = \frac{1}{N}\sum_{i=1}^{N}(ai-N)$$</p>
<p>and find the value of a that yeilds ME=0, which turn out to be</p>
<p>$$a = \frac{2N}{N+1}$$</p>
<p>which converges to 2 for large value of N, maming 2i as the estimator.</p>
<p>Hence, the three generated estimators are $i$ for <b>maximizing likelihood</b>, $3i/2$ for <b>minimizing squared error </b> and $2i$ as the <b>unbiased estimator</b>. Finally to compute the Bayesian posterior distribution, we compute</p>
<p>$$P(H_{n}|i) = \frac{P(i|H _{n}) P(H _{n})}{P(i)}$$</p>
<p>where $H_n$ is the hypothesis that there are $n$ trains and $i$ is the evidence that we saw train $i$. $P(i| H_n)$ is 1\n. The normalizing constant P(i) is just the sum of the numerators for each hypothesis.</p>


                

                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/post/chapter-7-hypothesis-testing/" data-toggle="tooltip" data-placement="top" title="Think Stats: Chapter 7">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/post/chapter-9-correlation/" data-toggle="tooltip" data-placement="top" title="Think Stats: Chapter 9">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>
                

            </div>

            
            
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
            

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                        
                        
                        
                        <a href="/tags/alternate-hypothesis" title="alternate-hypothesis">
                            alternate-hypothesis
                        </a>
                        
                        
                        
                        <a href="/tags/applied" title="applied">
                            applied
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/bernoulli-distribution" title="bernoulli-distribution">
                            bernoulli-distribution
                        </a>
                        
                        
                        
                        <a href="/tags/binomial-distribution" title="binomial-distribution">
                            binomial-distribution
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/cdf" title="cdf">
                            cdf
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/classification" title="classification">
                            classification
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/column-space" title="column-space">
                            column-space
                        </a>
                        
                        
                        
                        <a href="/tags/conceptual" title="conceptual">
                            conceptual
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/confidence-intervals" title="confidence-intervals">
                            confidence-intervals
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/exercises" title="exercises">
                            exercises
                        </a>
                        
                        
                        
                        <a href="/tags/exponential-distribution" title="exponential-distribution">
                            exponential-distribution
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/gilbert-strang" title="gilbert-strang">
                            gilbert-strang
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/hypothesis-testing" title="hypothesis-testing">
                            hypothesis-testing
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/islr" title="islr">
                            islr
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/linear-algebra" title="linear-algebra">
                            linear-algebra
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/linear-equations" title="linear-equations">
                            linear-equations
                        </a>
                        
                        
                        
                        <a href="/tags/linear-model-selection" title="linear-model-selection">
                            linear-model-selection
                        </a>
                        
                        
                        
                        <a href="/tags/linear-regression" title="linear-regression">
                            linear-regression
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/matrix-factorization" title="matrix-factorization">
                            matrix-factorization
                        </a>
                        
                        
                        
                        <a href="/tags/matrix-multiplications" title="matrix-multiplications">
                            matrix-multiplications
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/mean" title="mean">
                            mean
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/moving-beyond-linearity" title="moving-beyond-linearity">
                            moving-beyond-linearity
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/normal-distribution" title="normal-distribution">
                            normal-distribution
                        </a>
                        
                        
                        
                        <a href="/tags/null-hypothesis" title="null-hypothesis">
                            null-hypothesis
                        </a>
                        
                        
                        
                        <a href="/tags/null-space" title="null-space">
                            null-space
                        </a>
                        
                        
                        
                        <a href="/tags/one-tailed-test" title="one-tailed-test">
                            one-tailed-test
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/pmf" title="pmf">
                            pmf
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/power" title="power">
                            power
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/random-variables" title="random-variables">
                            random-variables
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/regularization" title="regularization">
                            regularization
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/resampling" title="resampling">
                            resampling
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/statistical-learning" title="statistical-learning">
                            statistical-learning
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/students-t-distribution" title="students-t-distribution">
                            students-t-distribution
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/subspace" title="subspace">
                            subspace
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/support-vector-machines" title="support-vector-machines">
                            support-vector-machines
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/think-stats" title="think-stats">
                            think-stats
                        </a>
                        
                        
                        
                        <a href="/tags/tree-based-methods" title="tree-based-methods">
                            tree-based-methods
                        </a>
                        
                        
                        
                        <a href="/tags/two-tailed-test" title="two-tailed-test">
                            two-tailed-test
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/unsupervised-learning" title="unsupervised-learning">
                            unsupervised-learning
                        </a>
                        
                        
                        
                        <a href="/tags/variance" title="variance">
                            variance
                        </a>
                        
                        
                        
                        <a href="/tags/vector-space" title="vector-space">
                            vector-space
                        </a>
                        
                        
                        
                        
                        
                        
                    </div>
                </section>
                

                
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                   
                   <li>
                       <a href='' rel="alternate" type="application/rss+xml" title="Amit Rajan" >
                           <span class="fa-stack fa-lg">
                               <i class="fas fa-circle fa-stack-2x"></i>
                               <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
                           </span>
                       </a>
                   </li>
                   
                    
                    <li>
                        <a href="mailto:amitrajan012@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    

                    
                    
                    

                    

		    
                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/amitrajan012">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/amit-rajan-1343aaba/">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    
                    
            
            
            
                </ul>
		<p class="copyright text-muted">
                    Copyright &copy; Amit Rajan 2022
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function loadAsync(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        loadAsync("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    loadAsync("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>









<script type="text/javascript">
    function generateCatalog(selector) {

        
        
        
        
            _containerSelector = 'div.post-container'
        

        
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        
        $(selector).html('')

        
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    


    loadAsync("\/js\/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>


</body>
</html>
