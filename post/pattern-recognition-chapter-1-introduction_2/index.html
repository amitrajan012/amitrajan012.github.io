<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="Amit Rajan">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://amitrajan012.github.io/img/head.jpg">
    <meta property="twitter:image" content="https://amitrajan012.github.io/img/head.jpg" />
    

    
    <meta name="title" content="Probability Theory" />
    <meta property="og:title" content="Probability Theory" />
    <meta property="twitter:title" content="Probability Theory" />
    

    
    <meta name="description" content="Pattern Recognition (Bishop): Chapter 1">
    <meta property="og:description" content="Pattern Recognition (Bishop): Chapter 1" />
    <meta property="twitter:description" content="Pattern Recognition (Bishop): Chapter 1" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="Amit, Rajan, ML, Data, Science, Blockchain">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>Probability Theory-Amit Rajan Blog</title>

    <link rel="canonical" href="/post/pattern-recognition-chapter-1-introduction_2/">

    
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hugo-theme-cleanwhite.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" rel="stylesheet" type="text/css">

    
    

    

    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
    }});</script>

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
    <script src="/js/jquery.min.js"></script>

    
    <script src="/js/bootstrap.min.js"></script>

    
    <script src="/js/hux-blog.min.js"></script>

    
    

</head>




<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Amit Rajan</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                        
                    
                    
		    
                        <li><a href="/top/about/">ABOUT</a></li>
                    

                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/head.jpg')
    }
</style>

<header class="intro-header" >

    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/bishop" title="Bishop">
                            Bishop
                        </a>
                        
                        <a class="tag" href="/tags/pattern-recognition" title="Pattern Recognition">
                            Pattern Recognition
                        </a>
                        
                        <a class="tag" href="/tags/joint-probability" title="Joint Probability">
                            Joint Probability
                        </a>
                        
                        <a class="tag" href="/tags/marginal-probability" title="Marginal Probability">
                            Marginal Probability
                        </a>
                        
                        <a class="tag" href="/tags/conditional-probability" title="Conditional Probability">
                            Conditional Probability
                        </a>
                        
                        <a class="tag" href="/tags/bayes-rule" title="Bayes Rule">
                            Bayes Rule
                        </a>
                        
                        <a class="tag" href="/tags/prior-probability" title="Prior Probability">
                            Prior Probability
                        </a>
                        
                        <a class="tag" href="/tags/posterior-probability" title="Posterior Probability">
                            Posterior Probability
                        </a>
                        
                        <a class="tag" href="/tags/probability-desnities" title="Probability Desnities">
                            Probability Desnities
                        </a>
                        
                        <a class="tag" href="/tags/cumulative-distribution-function" title="Cumulative Distribution Function">
                            Cumulative Distribution Function
                        </a>
                        
                        <a class="tag" href="/tags/expectations" title="Expectations">
                            Expectations
                        </a>
                        
                        <a class="tag" href="/tags/covariances" title="Covariances">
                            Covariances
                        </a>
                        
                        <a class="tag" href="/tags/bayesian-probabilities" title="Bayesian Probabilities">
                            Bayesian Probabilities
                        </a>
                        
                        <a class="tag" href="/tags/likelihood-function" title="Likelihood Function">
                            Likelihood Function
                        </a>
                        
                        <a class="tag" href="/tags/gaussian-distribution" title="Gaussian Distribution">
                            Gaussian Distribution
                        </a>
                        
                        <a class="tag" href="/tags/precision" title="Precision">
                            Precision
                        </a>
                        
                        <a class="tag" href="/tags/iid-samples" title="IID Samples">
                            IID Samples
                        </a>
                        
                        <a class="tag" href="/tags/maximum-likelihood-estimator" title="Maximum Likelihood Estimator">
                            Maximum Likelihood Estimator
                        </a>
                        
                    </div>
                    <h1>Probability Theory</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        
                            Posted by 
                            
                                    Amit Rajan
                             
                            on 
                            Monday, May 23, 2022
                            
                            
                            
                            
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <h2 id="12-probability-theory">1.2 Probability Theory</h2>
<p>Consider two random variables $X,Y$ where $X$ can take any of the values $x_i$ where $i=1,2,&hellip;,M$ and $Y$ can take the values $y_j$ where $j=1,2,&hellip;,L$. In a total of $N$ trials, both $X,Y$ are sampled and the number of trials for which $X=x_i,Y=y_j$ is $n_{ij}$. The number of trials in which $X=x_i$ is $c_i$ and $Y=y_j$ is $r_j$ respectively. Then, the <b>joint probability</b> of $X$ taking the value $x_i$ and $Y$ taking the value $y_j$ is given as:</p>
<p>$$\begin{align}
p(X=x_i,Y=y_j) = \frac{n_{ij}}{N}
\end{align}$$</p>
<p>The <b>marginal probability</b> of $X$ taking the value $x_i$ irrespective of the value of $Y$ is given as:</p>
<p>$$\begin{align}
p(X=x_i) = \frac{c_{i}}{N} = \sum_{j=1}^{L}p(X=x_i,Y=y_j)
\end{align}$$</p>
<p>where $c_i = \sum_{j}n_{ij}$. This is also called as the <b>sum rule of probability</b>. For $X=x_i$, the fraction of instances for which $Y=y_j$ is called as <b>conditional probability</b> of $Y=y_j$ given $X=x_i$ and is given as:</p>
<p>$$\begin{align}
p(Y=y_j|X=x_i) = \frac{n_{ij}}{c_{i}} = \frac{p(X=x_i,Y=y_j)}{p(X=x_i)}
\end{align}$$</p>
<p>This relation is also called as <b>produt rule of probability</b>. We can simply denote the joint and marginal probability as $p(X,Y)$(probability of $X$ and $Y$) and $p(Y|X)$ (probability of $Y$ given $X$). The <b>Bayes&rsquo; Rule</b> of probability is given as:</p>
<p>$$\begin{align}
p(Y|X) = \frac{p(X|Y)p(Y)}{p(X)}
\end{align}$$</p>
<p>where the denominator is:</p>
<p>$$\begin{align}
p(X) = \sum_{Y}p(X|Y)p(Y)
\end{align}$$</p>
<p>$X$ and $Y$ are said to be <b>independent</b> if $p(X,Y) = p(X)p(Y)$. <b>Prior probability</b> expresses the probability before some evidence is taken into account. <b>Posterior probability</b> expresses the probability after some evidence is taken into account.</p>
<h3 id="121-probability-desnities">1.2.1 Probability Desnities</h3>
<p>For <b>continuous variables</b>, probability can be computed using <b>probability densities</b>. If the probability of a real-valued variable $x$ falling in the range $(x, x+\delta x)$ is given as $p(x)\delta x$ for $\delta x \to 0$, then $p(x)$ is called the <b>probability density</b> over $x$. The probability that $x$ will lie in the interval $(a,b)$ is given as:</p>
<p>$$\begin{align}
p(x \in (a,b)) = \int_{a}^{b}p(x)dx
\end{align}$$</p>
<p>It should be noted that $p(x) \geq 0$ and $\int_{-\infty}^{\infty}p(x)dx = 1$. Let there be a change of variable $x = g(y)$ where the probability density functions are $p_x(x)$ and $p_y(y)$ with $p_x(x) \simeq p_y(y)$. Hence,</p>
<p>$$\begin{align}
p_y(y) = p_x(x)\left| \frac{dx}{dy} \right| = p_x(g(y))\left| g^{&rsquo;}(y) \right|
\end{align}$$</p>
<p>For any continuos variable $x$, the probability that it lies in the interval $(\infty, z)$ is given by <b>cumulative distribution function</b> which is defined as</p>
<p>$$\begin{align}
P(z) = \int_{-\infty}^{z}p(x)dx
\end{align}$$</p>
<p>and satisfies $P^{&rsquo;}(x) = p(x)$. For the continuous case, the <b>sum</b> and <b>product</b> rule takes the form</p>
<p>$$\begin{align}
p(x) = \int p(x,y)dy
\end{align}$$</p>
<p>$$\begin{align}
p(y|x) = \frac{p(x,y)}{p(x)}
\end{align}$$</p>
<p>When $x$ is <b>discrete</b>, $p(x)$ is called as <b>probability mass function</b>.</p>
<h3 id="122-expectations-and-covariances">1.2.2 Expectations and Covariances</h3>
<p>Average value of any function $f(x)$ under a probability distribution $p(x)$ is called as the <b>Expectation</b> of $f(x)$ and is denoted as $E[f]$. For discrete distribution, it is given as:</p>
<p>$$\begin{align}
E[f] = \sum_{x}f(x)p(x)
\end{align}$$</p>
<p>For continuous distribution, it is given as:</p>
<p>$$\begin{align}
E[f] = \int f(x)p(x)dx
\end{align}$$</p>
<p>For $N$ finite points drawn from a continuous distribution, the expectation can be estimated as:</p>
<p>$$\begin{align}
E[f] \simeq \frac{1}{N} \sum_{n=1}^{N} f(x_n)
\end{align}$$</p>
<p>For a function of two variables $f(x,y)$, the average of the function with respect to the distribution of $x$ is denoted as $E_{x}[f(x,y)]$. <b>Variance</b> of $f(x)$ is defined as:</p>
<p>$$\begin{align}
var[f] = E[(f(x) - E[f(x)])^2] = E[f(x)^2] - E[f(x)]^2
\end{align}$$</p>
<p>which defines how much variability is there in $f(x)$ around its mean value $E[f(x)]$. In the case of <b>two vectors of random variables</b> $x$ and $y$, the <b>covariance</b> is a matrix defined as</p>
<p>$$\begin{align}
cov[x,y] = E_{x,y}[(x-E[x])(y^T - E[y^T])] = E_{x,y}[xy^T] - E[x]E[y^T]
\end{align}$$</p>
<p>It should be noted that $cov[x] = cov[x,x]$.</p>
<h3 id="123-bayesian-probabilities">1.2.3 Bayesian Probabilities</h3>
<p><b>Bayes&rsquo; Theorem</b> can be used to convert <b>prior probability</b> to <b>posterior probability</b> by incorporating the evidence provided by the <b>observed data</b>. We can adopt this approach when making inferences about the quantities such as parameters $\mathbf{w}$ in the polynomial curve fitting example. We can encode our assumption about $\mathbf{w}$ as its <b>prior distribution</b> $p(\mathbf{w})$ befor observing the data. The distribution of observed data $D= (t_1, t_2, &hellip;, t_n)$ given prior $\mathbf{w}$ is encoded as $p(D|\mathbf{w})$. Then, Bayes&rsquo; Theorem can be used to derive the <b>posterior distribution</b> $p(\mathbf{w}|D)$ as</p>
<p>$$\begin{align}
p(\mathbf{w}|D) = \frac{p(D|\mathbf{w})p(\mathbf{w})}{p(D)}
\end{align}$$</p>
<p>$p(D|\mathbf{w})$ is expresses how probable the observed data $D$ is for different settings of the parameter vector $\mathbf{w}$. It is called as the <b>likelihood function</b>. The denominator $p(D)$ can be computed as $p(D) = \int p(D|\mathbf{w})p(\mathbf{w})d\mathbf{w}$.</p>
<p>In a <b>frequentist</b> setting, a widely used estimator is a <b>maximum likelihood estimator</b>. In maximum likelihood estimator, $\mathbf{w}$ is set to a value which maximizes the likelihood function $p(D|\mathbf{w})$. The negative log of the likelihood function is called as the <b>error function</b>. As negative logarithm is monotonically decreasing, maximizing the likelihood is equivalent to minimizing the error function.</p>
<p>In a <b>Bayesian</b> setting, we choose <b>prior distributions</b> $p(\mathbf{w})$ and $p(D|\mathbf{w})$, which are then used to compute the <b>posterior distributions</b> $p(\mathbf{w}|D)$. One criticisim of this approach is that these prior distributions are often chosen as per the mathematical convenience rather than as a reflection of prior beliefs. Reducing the dependence on prior is one motive for <b>noninformative</b> priors which may lead to better results.</p>
<h3 id="124-the-gaussian-distribution">1.2.4 The Gaussian Distribution</h3>
<p>For a real-valued variable $x$, the <b>gaussian</b> or <b>normal</b> distribution is defined as:</p>
<p>$$\begin{align}
N(x|\mu,\sigma^2) = \frac{1}{(2\pi\sigma^2)^{1/2}}exp\left\{{\frac{-1}{2\sigma^2}(x-\mu)^2}\right\}
\end{align}$$</p>
<p>where $\mu$ is the <b>mean</b> and $\sigma^2$ being <b>variance</b> ($\sigma$ being <b>standard deviation</b>). Reciprocal of the variance $\beta = \frac{1}{\sigma^2}$ is called as <b>precision</b>. Being a probability distribution, it satisfies following properties.</p>
<p>$$\begin{align}
N(x|\mu,\sigma^2) &gt; 0
\end{align}$$</p>
<p>$$\begin{align}
\int_{-\infty}^{\infty}N(x|\mu,\sigma^2)dx = 1
\end{align}$$</p>
<p>The mean and variance of the gaussian distribution can be calculated as:</p>
<p>$$\begin{align}
E[x] = \int_{-\infty}^{\infty}N(x|\mu,\sigma^2)xdx = \mu
\end{align}$$</p>
<p>$$\begin{align}
E[x^2] = \int_{-\infty}^{\infty}N(x|\mu,\sigma^2)x^2dx = \mu^2 + \sigma^2
\end{align}$$</p>
<p>$$\begin{align}
var[x] = E[x^2] - E[x]^2 = \sigma^2
\end{align}$$</p>
<p>Let us suppose we want to determine the parameters of a gaussian distribution ($\mu, \sigma^2$) based on $N$ points drawn from it. Let these observations are $\mathbf{x} = (x_1, x_2, &hellip;, x_N)^T$ where they are drawn independenty from the same gaussian distribution (called as <b>independent and identically distributed</b>). As they are independent, we can write</p>
<p>$$\begin{align}
p(\mathbf{x}|\mu,\sigma^2) = \prod_{n=1}^{N}N(x_n|\mu,\sigma^2)
\end{align}$$</p>
<p>This is the <b>likelihood function of a gaussian distribution</b>. The goal is to find the values of parematers $\mu$ and $\sigma^2$ which maximize this likelihood function. Instead of maximizing the likelihood function, we can maximize the log of it.</p>
<p>$$\begin{align}
ln(p(\mathbf{x}|\mu,\sigma^2)) = \sum_{n=1}^{N}ln[N(x_n|\mu,\sigma^2)]
\end{align}$$</p>
<p>$$\begin{align}
= \frac{-1}{2\sigma^2}\sum_{n=1}^{N}(x_n - \mu)^2 - \frac{N}{2}ln(2\pi) - \frac{N}{2}ln(\sigma^2)
\end{align}$$</p>
<p>Taking derivative with respect to $\mu$ and equating it to $0$, we get</p>
<p>$$\begin{align}
\mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_n
\end{align}$$</p>
<p>which is the <b>sample mean</b>. Taking the derivative with respect to $\sigma^2$ and equating it to 0, we get</p>
<p>$$\begin{align}
\sigma^2_{ML} = \frac{1}{N}\sum_{n=1}^{N}(x_n - \mu_{ML})^2
\end{align}$$</p>
<p>which is the <b>sample variance measured w.r.t. the sample mean</b>. <b>Maximum likelihood estimators</b> for mean and varince are functions of data set values $x_1, x_2, &hellip;, x_n$. Considering the expectations of these quantities with respect to the data set values, we get</p>
<p>$$\begin{align}
E[\mu_{ML}] = \mu
\end{align}$$</p>
<p>$$\begin{align}
E[\sigma^2_{ML}] = \left(\frac{N-1}{N}\right)\sigma^2
\end{align}$$</p>
<p>Hence, maximum likelihood estimator will underestimate the true variance by a factor of $\frac{N-1}{N}$. The <b>unbiased estimate</b> of variance is</p>
<p>$$\begin{align}
\tilde{\sigma}^2 = \left(\frac{N}{N-1}\right)\sigma^2_{ML} = \frac{1}{N-1}\sum_{n=1}^{N}(x_n - \mu_{ML})^2
\end{align}$$</p>
<h3 id="125-curve-fitting-re-visited">1.2.5 Curve fitting re-visited</h3>
<p>The curve fitting example can be seen as deriving a polynomial function $y(x,\mathbf{w})$ which has parameters $\mathbf{w}$ and input $x$. The predicted value $y(x,\mathbf{w})$ should be as close as possible to the target $t$. We can assume that for a given value of $x$, the corresponding value of $t$ follows a <b>gaussian distribution</b> with mean $y(x,\mathbf{w})$ and variance $\sigma^2$ (or precision $\beta = \frac{1}{\sigma^2}$). This is depicted in the below figure.</p>
<img class="pure-img" src="/img/pattern_recognition/curve_fitting.png" alt="">
<p>Hence, we have</p>
<p>$$\begin{align}
p(t | x, \mathbf{w}, \beta) = N(t|y(x,\mathbf{w}),\beta^{-1})
\end{align}$$</p>
<p>We have to maximize the likelihood for the entire training dataset $\mathbf{{x,t}}$, which is $p(\mathbf{t | x}, \mathbf{w}, \beta)$ to get the value of $\mathbf{w}$ and $\beta$. If we assume that the data is drawn independently from the distribution, the maximum likelihood function is given as</p>
<p>$$\begin{align}
p(\mathbf{t|x}, \mathbf{w}, \beta) = \prod_{n=1}^{N}N(t_n|y(x_n,\mathbf{w}),\beta^{-1})
\end{align}$$</p>
<p>Taking the logarithm, we get</p>
<p>$$\begin{align}
ln(p(\mathbf{t|x}, \mathbf{w}, \beta)) = \frac{-\beta}{2}\sum_{n=1}^{N}{y(x_n,\mathbf{w}) - t_n}^2 - \frac{N}{2}ln(2\pi) + \frac{N}{2}ln(\beta)
\end{align}$$</p>
<p>The maximum likelihood estimator of the polynomial coefficient $\mathbf{w}$ deonted as $\mathbf{w_{ML}}$ is obtained by maximizing the log likelihood with respect to $\mathbf{w}$. As the last two terms $- \frac{N}{2}ln(2\pi) + \frac{N}{2}ln(\beta)$ does not depend on $\mathbf{w}$, we can omit them, i.e. we simply have to maximize $\frac{-\beta}{2}\sum_{n=1}^{N}{y(x_n,\mathbf{w}) - t_n}^2$ w.r.t. $\mathbf{w}$. $\beta$ being a constant, we can remove it and by reversing the sign, <b>we have to minimize</b> $\frac{1}{2}\sum_{n=1}^{N}{y(x_n,\mathbf{w}) - t_n}^2$, which is the <b>sum of squares error fucntion</b>. Hence, <b>the sum-of-squares error function has arisen as a consequence of maximizing likelihood under the assumption of a Gaussian noise distribution</b>. Maximizing w.r.t. $\beta$, we get</p>
<p>$$\begin{align}
\beta_{ML} = \frac{1}{N}\sum_{n=1}^{N}\{y(x_n,\mathbf{w_{ML}}) - t_n\}^2
\end{align}$$</p>
<p>Using the bayseian approach, we can even get the error in predictio of $t$ as we get the <b>predictive distribution</b> over $t$ instead of just a point estimate. The predictive distribution is given as</p>
<p>$$\begin{align}
p(t | x, \mathbf{w_{ML}}, \beta_{ML}) = N(t|y(x,\mathbf{w_{ML}}),\beta^{-1}_{ML})
\end{align}$$</p>
<p>If we further include the <b>prior distribution</b> of $\mathbf{w}$ and assume that it follows a <b>gaussian distribution</b> with mean $0$ and precision $\alpha$. As we know that the <b>multivaraite gaussian</b> for a $D$ dimensional vector is given as</p>
<p>$$\begin{align}
N(\mathbf{x|\mu,\Sigma}) = \frac{1}{(2\pi)^{D/2}} \frac{1}{|\mathbf{\Sigma}|^{1/2}} exp\left\{{\frac{-1}{2}(\mathbf{x-\mu})^T}\mathbf{\Sigma}^{-1}(\mathbf{x-\mu})\right\}
\end{align}$$</p>
<p>where $\mathbf{x,\mu}$ are $D$ dimensional vectors and $\mathbf{\Sigma}$ is a $D \times D$ <b>covariance matrix</b>. The covariance matrix for the distribution of $\mathbf{w}$ can be represented as $\mathbf{\Sigma} = \alpha^{-1}\mathbf{I}$, where $\mathbf{I}$ is a $(M+1) \times (M+1)$ matrix, which gives us $|\mathbf{\Sigma}| = \frac{1}{\alpha^{M+1}}$. Hence, we get</p>
<p>$$\begin{align}
p(\mathbf{w}|\alpha) = N(\mathbf{w} |0,\alpha^{-1}\mathbf{I}) = \left(\frac{\alpha}{2\pi}\right)^{(M+1)/2} exp\left\{{\frac{-\alpha}{2}\mathbf{w}^T}\mathbf{w}\right\}
\end{align}$$</p>
<p>Using Bayes&rsquo; Theorem, we have</p>
<p>$$\begin{align}
p(\mathbf{w|x,t},\alpha,\beta) \propto p(\mathbf{t|x,w},\beta) p(\mathbf{w}| \alpha)
\end{align}$$</p>
<p>We can now maximize the <b>posterior distribution</b> of $\mathbf{w}$ by taking the logarithm and following the similar process and we can eventually reach at the conclusion that we have to minimze the following term instead</p>
<p>$$\begin{align}
\frac{\beta}{2} \sum_{n=1}^{N}{y(x_n,\mathbf{w}) - t_n}^2 + \frac{\alpha}{2}\mathbf{w}^T\mathbf{w}
\end{align}$$</p>
<p>Hence, <b>maximizing the posterior distribution is equivalent to minimizing the regularized sum-of-squares error function</b>.</p>


                

                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/post/pattern-recognition-chapter-1-introduction_1/" data-toggle="tooltip" data-placement="top" title="Polynomial Curve Fitting">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/post/pattern-recognition-chapter-1-introduction_3/" data-toggle="tooltip" data-placement="top" title="Model Selection &amp; Curse of Dimensionality">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>
                

            </div>

            
            
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
            

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                        
                        
                        
                        <a href="/tags/alternate-hypothesis" title="alternate-hypothesis">
                            alternate-hypothesis
                        </a>
                        
                        
                        
                        <a href="/tags/applied" title="applied">
                            applied
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/basis" title="basis">
                            basis
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/bernoulli-distribution" title="bernoulli-distribution">
                            bernoulli-distribution
                        </a>
                        
                        
                        
                        <a href="/tags/binomial-distribution" title="binomial-distribution">
                            binomial-distribution
                        </a>
                        
                        
                        
                        <a href="/tags/bishop" title="bishop">
                            bishop
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/cdf" title="cdf">
                            cdf
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/classification" title="classification">
                            classification
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/column-space" title="column-space">
                            column-space
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/conceptual" title="conceptual">
                            conceptual
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/confidence-intervals" title="confidence-intervals">
                            confidence-intervals
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/cross-validation" title="cross-validation">
                            cross-validation
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/determinant" title="determinant">
                            determinant
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/dimension" title="dimension">
                            dimension
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/eigenvalue-decomposition" title="eigenvalue-decomposition">
                            eigenvalue-decomposition
                        </a>
                        
                        
                        
                        <a href="/tags/eigenvalues" title="eigenvalues">
                            eigenvalues
                        </a>
                        
                        
                        
                        <a href="/tags/eigenvectors" title="eigenvectors">
                            eigenvectors
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/exercises" title="exercises">
                            exercises
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/exponential-distribution" title="exponential-distribution">
                            exponential-distribution
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/gilbert-strang" title="gilbert-strang">
                            gilbert-strang
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/hypothesis-testing" title="hypothesis-testing">
                            hypothesis-testing
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/islr" title="islr">
                            islr
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/linear-algebra" title="linear-algebra">
                            linear-algebra
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/linear-equations" title="linear-equations">
                            linear-equations
                        </a>
                        
                        
                        
                        <a href="/tags/linear-model-selection" title="linear-model-selection">
                            linear-model-selection
                        </a>
                        
                        
                        
                        <a href="/tags/linear-regression" title="linear-regression">
                            linear-regression
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/matrix-factorization" title="matrix-factorization">
                            matrix-factorization
                        </a>
                        
                        
                        
                        <a href="/tags/matrix-multiplications" title="matrix-multiplications">
                            matrix-multiplications
                        </a>
                        
                        
                        
                        <a href="/tags/matrix-space" title="matrix-space">
                            matrix-space
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/mean" title="mean">
                            mean
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/moving-beyond-linearity" title="moving-beyond-linearity">
                            moving-beyond-linearity
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/normal-distribution" title="normal-distribution">
                            normal-distribution
                        </a>
                        
                        
                        
                        <a href="/tags/null-hypothesis" title="null-hypothesis">
                            null-hypothesis
                        </a>
                        
                        
                        
                        <a href="/tags/null-space" title="null-space">
                            null-space
                        </a>
                        
                        
                        
                        <a href="/tags/one-tailed-test" title="one-tailed-test">
                            one-tailed-test
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/pattern-recognition" title="pattern-recognition">
                            pattern-recognition
                        </a>
                        
                        
                        
                        <a href="/tags/pmf" title="pmf">
                            pmf
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/power" title="power">
                            power
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/projection" title="projection">
                            projection
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/random-variables" title="random-variables">
                            random-variables
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/regularization" title="regularization">
                            regularization
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/resampling" title="resampling">
                            resampling
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/statistical-learning" title="statistical-learning">
                            statistical-learning
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/students-t-distribution" title="students-t-distribution">
                            students-t-distribution
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/subspace" title="subspace">
                            subspace
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/support-vector-machines" title="support-vector-machines">
                            support-vector-machines
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/think-stats" title="think-stats">
                            think-stats
                        </a>
                        
                        
                        
                        <a href="/tags/tree-based-methods" title="tree-based-methods">
                            tree-based-methods
                        </a>
                        
                        
                        
                        <a href="/tags/two-tailed-test" title="two-tailed-test">
                            two-tailed-test
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/unsupervised-learning" title="unsupervised-learning">
                            unsupervised-learning
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/variance" title="variance">
                            variance
                        </a>
                        
                        
                        
                        <a href="/tags/vector-space" title="vector-space">
                            vector-space
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                    </div>
                </section>
                

                
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                   
                   <li>
                       <a href='' rel="alternate" type="application/rss+xml" title="Amit Rajan" >
                           <span class="fa-stack fa-lg">
                               <i class="fas fa-circle fa-stack-2x"></i>
                               <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
                           </span>
                       </a>
                   </li>
                   
                    
                    <li>
                        <a href="mailto:amitrajan012@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    

                    
                    
                    

                    

		    
                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/amitrajan012">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/amit-rajan-1343aaba/">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    
                    
            
            
            
                </ul>
		<p class="copyright text-muted">
                    Copyright &copy; Amit Rajan 2022
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function loadAsync(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        loadAsync("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    loadAsync("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>









<script type="text/javascript">
    function generateCatalog(selector) {

        
        
        
        
            _containerSelector = 'div.post-container'
        

        
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        
        $(selector).html('')

        
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    


    loadAsync("\/js\/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>


</body>
</html>
