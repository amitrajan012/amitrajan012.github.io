<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Activation Function on Amit Rajan</title>
    <link>https://amitrajan012.github.io/tags/activation-function/</link>
    <description>Recent content in Activation Function on Amit Rajan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 09 Jul 2022 23:07:28 +0100</lastBuildDate><atom:link href="https://amitrajan012.github.io/tags/activation-function/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Neural Networks - Feed-forward Network Functions</title>
      <link>https://amitrajan012.github.io/post/pattern-recognition-chapter-5-neural-networks_1/</link>
      <pubDate>Sat, 09 Jul 2022 23:07:28 +0100</pubDate>
      
      <guid>https://amitrajan012.github.io/post/pattern-recognition-chapter-5-neural-networks_1/</guid>
      <description>One of the major limitations of the modeling techniques discussed so far is the way fixed basis functions are used to defind the transformation of data points. This approach leads to a much sparser models. An alternative approach is to fix the number of basis functions in advance but allow them to be adaptive, in other words to use parametric forms for the basis functions in which the parameter values are adapted during training.</description>
    </item>
    
  </channel>
</rss>
