<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Support Vector Classifiers on Amit Rajan</title>
    <link>https://amitrajan012.github.io/tags/support-vector-classifiers/</link>
    <description>Recent content in Support Vector Classifiers on Amit Rajan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Jun 2018 02:24:24 +0100</lastBuildDate><atom:link href="https://amitrajan012.github.io/tags/support-vector-classifiers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ISLR Chapter 9: Support Vector Machines (Part 2: Support Vector Classifiers)</title>
      <link>https://amitrajan012.github.io/post/support-vector-machines_part2/</link>
      <pubDate>Wed, 20 Jun 2018 02:24:24 +0100</pubDate>
      
      <guid>https://amitrajan012.github.io/post/support-vector-machines_part2/</guid>
      <description>9.2 Support Vector Classifiers 9.2.1 Overview of the Support Vector Classifier The maximal margin classifiers can be sensitive to individual observations. Sometimes, adding a single observation in the data set, can lead to dramatic change in the separating hyperplane. The sensitivity and the low margin for a maximal margin classifier may suggest that the maximal margin classifier has overfit the training data. So, sometimes we may be willing to consider a classifier based on a hyperplane that does not perfectly separate the two classes, and hence, will be more robust (or less sensitive to individual observations) and will give better results for the unseen data points.</description>
    </item>
    
  </channel>
</rss>
