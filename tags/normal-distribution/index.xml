<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Normal Distribution on Amit Rajan</title>
    <link>https://amitrajan012.github.io/tags/normal-distribution/</link>
    <description>Recent content in Normal Distribution on Amit Rajan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 Nov 2018 07:26:51 +0530</lastBuildDate><atom:link href="https://amitrajan012.github.io/tags/normal-distribution/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hypothesis Testing (Part 6)</title>
      <link>https://amitrajan012.github.io/post/detailed-hypothesis-testing_6/</link>
      <pubDate>Mon, 26 Nov 2018 07:26:51 +0530</pubDate>
      
      <guid>https://amitrajan012.github.io/post/detailed-hypothesis-testing_6/</guid>
      <description>### Tests for Variances of Normal Populations : Let $X_1, X_2, &amp;hellip;, X_n$ be a simple random sample from a normal population given as $N(\mu, \sigma^2)$. The sample variance $s^2$ is given as:
$$s^2 = \frac{1}{n-1}\sum_{i=1}^{n} (X_i - \overline{X})^2$$
Then the test statistic $\frac{(n-1)s^2}{\sigma_0^2}$ follows a chi-square distribution with $n-1$ degrees of freedom. The null hypothesis can take any of the form:
$$H_0: \sigma^2 \leq \sigma_0^2;\ \sigma^2 = \sigma_0^2;\ \sigma^2 \geq \sigma_0^2$$</description>
    </item>
    
    <item>
      <title>Confidence Intervals (Part 1)</title>
      <link>https://amitrajan012.github.io/post/confidence-intervals_1/</link>
      <pubDate>Sat, 17 Nov 2018 11:27:09 +0530</pubDate>
      
      <guid>https://amitrajan012.github.io/post/confidence-intervals_1/</guid>
      <description>A confidence interval is a type of interval estimate, computed from the statistics of the observed data, that might contain the true value of an unknown population parameter. The interval has an associated confidence level that, loosely speaking, quantifies the level of confidence that the parameter lies in the interval.  #### Confidence Intervals for a Population Mean (Large-Sample) : For $X_1, X_2, &amp;hellip;, X_n$ be a large ($n &amp;gt; 30$) random sample from a population with mean $\mu$ and standard deviation $\sigma$, so that $\overline{X}$ is approximately normal (from Central Limit Theorem).</description>
    </item>
    
    <item>
      <title>Commonly used Distributions (Part 2)</title>
      <link>https://amitrajan012.github.io/post/commonly-used-distributions_2/</link>
      <pubDate>Fri, 16 Nov 2018 01:00:00 +0530</pubDate>
      
      <guid>https://amitrajan012.github.io/post/commonly-used-distributions_2/</guid>
      <description>#### The Normal Distribution : The normal distribution is a continuous distribution with any mean and a positive variance. The probability density function of a normal distribution with mean $\mu$ and variance $\sigma^2$ is given as:
$$f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$
The above normal distribution is denoted as $X \sim N(\mu, \sigma^2)$ with mean and variance as:
$$\mu_X = \mu$$
$$\sigma_X^2 = \sigma^2$$
For a normal distribution, about 68% of the population is in the interval $\mu \pm \sigma$, 95% in $\mu \pm 2\sigma$ and 99.</description>
    </item>
    
    <item>
      <title>Maximum Likelihood Estimation</title>
      <link>https://amitrajan012.github.io/post/maximum-likelihood-estimation-/</link>
      <pubDate>Sun, 28 Oct 2018 17:11:47 +0100</pubDate>
      
      <guid>https://amitrajan012.github.io/post/maximum-likelihood-estimation-/</guid>
      <description>### Introduction : Maximum Likelihood Estimation is the method of estimating the parameters of a statistical model, given the observations. It attempts to find the parameter values that maximize the likelihood function. The process can be viewed as finding the parameters that maximize the likelihood of getting the data we observed for a particular set of statistical models.
Suppose we have the data points (random samples) $X_1, X_2, &amp;hellip;, X_n$ which belong to a distribution which depends on one or more unknown parameters $\theta_1, \theta_2, &amp;hellip;, \theta_m$ with probability density (or mass) function $f(x_i; \theta_1, \theta_2, &amp;hellip;, \theta_m)$.</description>
    </item>
    
    <item>
      <title>Naive Bayes Classifier</title>
      <link>https://amitrajan012.github.io/post/naive-bayes-classifier/</link>
      <pubDate>Wed, 24 Oct 2018 05:01:19 +0100</pubDate>
      
      <guid>https://amitrajan012.github.io/post/naive-bayes-classifier/</guid>
      <description>Introduction : Naive Bayes is an extremely fast classification algorithm which uses Bayes Theorem as its basic building block. It assumes that the features or predictors in the dataset are independent.
The Bayes theorem is given as:
$$P(c|X) = \frac{P(c)P(X|c)}{P(X)}$$
where $c$ denotes a class label and $X$ is the predictor. The probabilities $P(c)$ and $P(X)$ are the prior probabilities of the class and the predictor. $P(X|c)$ is the prior probability or likelihood of observing a feature $X$ given class $c$.</description>
    </item>
    
    <item>
      <title>Think Stats: Chapter 4</title>
      <link>https://amitrajan012.github.io/post/chapter-4-continuous-distributions/</link>
      <pubDate>Fri, 17 Aug 2018 19:02:16 +0100</pubDate>
      
      <guid>https://amitrajan012.github.io/post/chapter-4-continuous-distributions/</guid>
      <description>4.1 The exponential distribution CDF of the exponential distribution is defined as (where lambda determines the shape of the distribution): $$CDF(x) = 1-e^{-\lambda x}$$ Mean and Median of exponential distribution is computed as follows: $$Mean = \frac{1}{\lambda}$$ $$Median = \frac{ln(2)}{\lambda}$$ In the real world, exponential distribution is encountered when we look at the series of events and measure the time between them which is called as interval times. The exponential distribution for different values of lambda is shown below.</description>
    </item>
    
  </channel>
</rss>
