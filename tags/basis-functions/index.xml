<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Basis Functions on Amit Rajan</title>
    <link>https://amitrajan012.github.io/tags/basis-functions/</link>
    <description>Recent content in Basis Functions on Amit Rajan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Jul 2022 23:07:28 +0100</lastBuildDate><atom:link href="https://amitrajan012.github.io/tags/basis-functions/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Linear Models for Clasification - Probabilistic Discriminative Models</title>
      <link>https://amitrajan012.github.io/post/pattern-recognition-chapter-4-linear-models-for-classification_8/</link>
      <pubDate>Tue, 05 Jul 2022 23:07:28 +0100</pubDate>
      
      <guid>https://amitrajan012.github.io/post/pattern-recognition-chapter-4-linear-models-for-classification_8/</guid>
      <description>4.3 Probabilistic Discriminative Models For two-class classification problem, the posterior probability of classes are the logistic sigmoid transformation of a linear function of input $X$. For multi-class classification problem, they are given by the softmax transformation of a linear function of input $X$. In maximum likelihood solution, we chose the class-conditional densities and then maximized the log likelihood to obtain posterior densities. However, an alternative approach is to use the functional form of the generalized linear model explicitly instead and to determine its parameters directly by using maximum likelihood.</description>
    </item>
    
    <item>
      <title>ISLR Chapter 7: Moving Beyond Linearity (Part 1: Polynomial Regression, Step Functions, Basis Functions)</title>
      <link>https://amitrajan012.github.io/post/moving-beyond-linearity_part1/</link>
      <pubDate>Mon, 28 May 2018 04:22:38 +0100</pubDate>
      
      <guid>https://amitrajan012.github.io/post/moving-beyond-linearity_part1/</guid>
      <description>Moving Beyond Linearity Lineaer models have its limitations in terms of predictive power. Linear models can be extended simply as:
Polynomial regression extends linear regression by adding extra higher order predictors (predictors rasied to higher order powers).
Step functions cut the range of a variable into $K$ distinct regions in order to produce a qualitative variable.
Regression splines is the extension of polynomial regression and step functions. It divides the range of predictor $X$ into $K$ distinct regions and within each region a polynomial function is fit to the data.</description>
    </item>
    
  </channel>
</rss>
